{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END TO END DATA PIPELINE PROJECT\n",
    "SCRAPPING DATA(HEADLINES, CORRESPONDING HYPERLINKS and STORY) FROM AN ONLINE NEWS WEBSITE (THEGUARDIAN.COM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries Successfully Imported!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as BS\n",
    "print(\"Libraries Successfully Imported!\")\n",
    "#In this cell, I basically imported the necessary package required to scrap the site i.e BEAUTIFULSOUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.theguardian.com/au\"\n",
    "extracting_data = requests.get(url).text\n",
    "wiki_data = BS(extracting_data, 'html.parser')\n",
    "\n",
    "# Here, I scrapped ALL of the contents on the page of the link as html tags using the \n",
    "# html.parser and the beautifulsoup package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Headlines = []      # I will be scrapping the news headline, story link and contents; 3 parameters\n",
    "links = []\n",
    "story =[]\n",
    "data = []       # Creating empty lists to hold our data\n",
    "i=0             # I created this int to serve as an iterator to iterate through the 'links' list and get the article contents for each link by incrementing it in every for loop\n",
    "\n",
    "for news in wiki_data.findAll('div' , {'class':'fc-item__container'}): # This is the tag where the headline and link is contained\n",
    "    datum = {} # An empty dict to hold the the scapped data\n",
    "    Headlines.append(news.text.replace('\\n',''))\n",
    "    links.append(news.a['href'])\n",
    "    page = requests.get(links[i])\n",
    "    Object = BS(page.content)\n",
    "    for news in Object.findAll('div',{'class':'article-body-commercial-selector'}): # This is the tag to get the story content for each of the links\n",
    "        story.append(news.text.replace('\\n',''))\n",
    "    \n",
    "        datum['Headlines'] = Headlines[i]\n",
    "        datum['Links'] = links[i]\n",
    "        datum ['Story'] = story[i]\n",
    "        data.append(datum) #The final list holding all of our data\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x20d8375e1d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# load_dotenv(find_dotenv())\n",
    "# password = os.environ.get(\"MONGODB\")\n",
    "\n",
    "conn_str = f\"mongodb+srv://pelvic:Pelvic4ever@cluster0.zst9xg2.mongodb.net/?retryWrites=true&w=majority\"\n",
    "client = MongoClient(conn_str)  # This is the link required to access my mongodb hosted on atlas\n",
    "db = client.Online_News.news # I then created a new collection in my 'Online_News' database\n",
    "db.insert_many(data) # I finally inserted all of my data into the database\n",
    "# dbs = client.list_database_names()\n",
    "# print(dbs)\n",
    "# testdb = client.Online_News\n",
    "# collections = testdb.list_collection_names()\n",
    "# print(collections)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('Kubeflow_Pipelines-master-oUkMXjJq')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ad50f5c4eb016e033faa80e5e094e3843f36ce778b98bf7ef2521b490b1589d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
